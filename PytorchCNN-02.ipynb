{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8193e130-6a8f-49b5-86a8-d0653c79c56e",
   "metadata": {},
   "source": [
    "# Challenging Fake Image Detection from GAN Models\n",
    "\n",
    "#### Detecting fake or manipulated images in today's digital age has become increasingly challenging due to the advancements in Generative Adversarial Networks (GANs). These AI-powered tools have made it easier than ever to create convincing fake images that can deceive both human observers and traditional image analysis techniques. The problem at hand is to develop a robust and effective fake image detection system that can differentiate between genuine and manipulated images generated by GAN models.\n",
    "\n",
    "### By: Shashidhar Y Bhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab79c804-09e5-4511-b0b7-418e65c7901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479d3636-fbaf-496e-949f-9ce0ea149226",
   "metadata": {},
   "source": [
    "### Adjustable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6110cf2-86c1-4899-adb9-cee8704ed8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./train/\" \n",
    "test_dir = \"./test/\"\n",
    "batch_size = 64\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "098c5e64-9408-48a6-8bf6-c1ee6a99967f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b747a88-77e9-45c8-88d2-5fed84bd2ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc35a93-1228-40f8-8f6a-db3748b13b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(train_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2619180b-bc26-46fc-91d0-7df3c1306c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "112018f3-101b-4573-ba56-ada9968cf586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5101270869765157\n",
      "Epoch 2, Loss: 0.42317306107805086\n",
      "Epoch 3, Loss: 0.3851573493948977\n",
      "Epoch 4, Loss: 0.3626243359983082\n",
      "Epoch 5, Loss: 0.35065844432901894\n",
      "Epoch 6, Loss: 0.3394696232567822\n",
      "Epoch 7, Loss: 0.33204978202980295\n",
      "Epoch 8, Loss: 0.32609326801884275\n",
      "Epoch 9, Loss: 0.32009835934989816\n",
      "Epoch 10, Loss: 0.31656102702660355\n",
      "Epoch 11, Loss: 0.30983269454879175\n",
      "Epoch 12, Loss: 0.3074976166356319\n",
      "Epoch 13, Loss: 0.3031492276940678\n",
      "Epoch 14, Loss: 0.30053549999715573\n",
      "Epoch 15, Loss: 0.2973550752958882\n",
      "Epoch 16, Loss: 0.29427219612699096\n",
      "Epoch 17, Loss: 0.29256950057590153\n",
      "Epoch 18, Loss: 0.28824524804520746\n",
      "Epoch 19, Loss: 0.2894555256056694\n",
      "Epoch 20, Loss: 0.2865192043384679\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc660792-33b3-4b90-a4c1-ecad43de44ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Dataset: 87.90%\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ImageFolder(test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predicted = (outputs >= 0.5).view(-1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on Test Dataset: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
